{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b362f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-21 19:21:36.572387: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807f44dc",
   "metadata": {},
   "source": [
    "Importing vectorizer, explained in train notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "686dc030",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_model = gensim.models.KeyedVectors.load_word2vec_format('cc.hr.300.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40e23b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_dataset.csv') #Loading test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066f52ca",
   "metadata": {},
   "source": [
    "**Feedforward neural network Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a9f409",
   "metadata": {},
   "source": [
    "Splitting dataset on x,y (words,lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe459d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words = df_test[\"Rijeci\"] \n",
    "test_lemmas = df_test[\"Leme\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8b0bfa",
   "metadata": {},
   "source": [
    "Explained in train notebook, used to save words and lemmas as a vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d76aa85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "\n",
    "def get_vec_form(words, lemmas):\n",
    "    x = {'form': [], 'vec': []}\n",
    "    y = {'form': [], 'vec': []}\n",
    "    for w, l in zip(words, lemmas):\n",
    "        try:\n",
    "            new_x = vec_model[w]\n",
    "        except:\n",
    "            vocab.add(w)\n",
    "            continue\n",
    "        try:\n",
    "            new_y = vec_model[l]\n",
    "        except:\n",
    "            vocab.add(l)\n",
    "            continue\n",
    "        x['vec'].append(new_x)\n",
    "        x['form'].append(w)\n",
    "        y['vec'].append(new_y)\n",
    "        y['form'].append(l)\n",
    "    x['vec'] = np.array(x['vec'])\n",
    "    y['vec'] = np.array(y['vec'])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "373272c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, test_y = get_vec_form(test_words, test_lemmas) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1db69438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51548"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_x['vec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbb65c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ffnn = tf.keras.models.load_model(\"model_ffnn.keras\") #loading exported model from train notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc36e958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1611/1611 [==============================] - 2s 1ms/step\n",
      "68.23%\t- F1 score on test set\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evaluate_f1(predicted_vecs, lemmas):\n",
    "    predicted_lemmas = []\n",
    "    # Iterating through predicted vectors and their corresponding indices\n",
    "    for i, pred in enumerate(predicted_vecs):\n",
    "        \n",
    "        #Finding the nearest lemma using vec_model\n",
    "        nearest = vec_model.most_similar(positive=[pred], topn=1)\n",
    "        \n",
    "        # Appending the predicted lemma if found, otherwise append an empty string\n",
    "        predicted_lemmas.append(nearest[0][0] if nearest else \"\")\n",
    "    \n",
    "    f1 = f1_score(lemmas, predicted_lemmas, average='micro') #using f1score pre-built function to obtain f1 score\n",
    "    return f1, predicted_lemmas\n",
    "\n",
    "# Predicting using a feedforward neural network model on the test set vectors\n",
    "test_pred_ffnn = model_ffnn.predict(test_x['vec'])\n",
    "\n",
    "f1_ffnn, predicted_lemmas_ffnn = evaluate_f1(test_pred_ffnn, test_y['form']) #applying function and getting f1 score\n",
    "\n",
    "\n",
    "print('{:.2f}%\\t- F1 score on test set'.format(100 * f1_ffnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d68c66",
   "metadata": {},
   "source": [
    "Evaluation on real-life examples to check our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb875075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(tokens):\n",
    "    lemmas = []\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            vec = vec_model[token].reshape((1, 300)) #vector representation\n",
    "            pred = model_ffnn.predict(vec)[0] #making a prediction using ffnn\n",
    "            #Finding the most similar lemma in the vector model based on the predicted vector\n",
    "            lemmas.append(vec_model.most_similar(positive=[pred], topn=1)[0][0])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(token)\n",
    "            lemmas.append(token)\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edf2eda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "\"Key 'posao,' not present\"\n",
      "posao,\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ići',\n",
       " 'biti',\n",
       " 'danas',\n",
       " 'na',\n",
       " 'posao,',\n",
       " 'biti',\n",
       " 'ja',\n",
       " 'biti',\n",
       " 'jako',\n",
       " 'zanimljiv',\n",
       " 'dan',\n",
       " 'na',\n",
       " 'posao']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(\"Išao sam danas na posao, bio mi je jako zanimljiv dan na poslu\".split(' ')) #lets try it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8930d1",
   "metadata": {},
   "source": [
    "**LSTM Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37be636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMmodel = tf.keras.models.load_model(\"lstm_model.keras\") #loading exported model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab46f77a",
   "metadata": {},
   "source": [
    "Using again dataset resized 10times because I cant run full LSTM on dataset, so to have same ratio as in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ac7806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words = df_test[\"Rijeci\"].values[:5154]\n",
    "test_lemmas = df_test[\"Leme\"].values[:5154]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c63966",
   "metadata": {},
   "source": [
    "Reused function from training for generating test batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03ef1450",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 50  # Batch size\n",
    "R = 300  # RNN size\n",
    "S = 4   # Max sequence length\n",
    "E = 300  # Embedding size -> dimensionality of the vector space in which words or tokens are represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61d5da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(words, lemmas, vec_model, line_limit=5145, mode='test'):\n",
    "    word_count = 0\n",
    "    line_number = 0\n",
    "\n",
    "    # Initialize arrays to store input (x) and output (y) sequences\n",
    "    x = np.zeros((B, S, E))\n",
    "    y = np.zeros((B, S, E))\n",
    "    \n",
    "    word_seqs = [None for _ in range(B)] # Stores word sequences\n",
    "    lemma_seqs = [None for _ in range(B)] # Stores lemma sequences\n",
    "\n",
    "    word_seq = [] # Current word sequence\n",
    "    lemma_seq = [] # Current lemma sequence\n",
    "    \n",
    "    x_seq = [] # Current x sequence\n",
    "    y_seq = [] # Current y sequence\n",
    "    \n",
    "    i = 0 # Batch index\n",
    "\n",
    "    \n",
    "    # Iterate through words and lemmas\n",
    "    for word, lemma in zip(words, lemmas):\n",
    "        line_number += 1\n",
    "        if line_number > line_limit: # Stopping if line limit is reached\n",
    "            return \n",
    "\n",
    "        # Check if the current sequences have reached the maximum length (S)\n",
    "        if len(x_seq) == S and len(y_seq) == S:\n",
    "            # Convert current sequences to arrays and store them in the batch\n",
    "            x[i] = np.array(x_seq)\n",
    "            y[i] = np.array(y_seq)\n",
    "            word_seqs[i] = word_seq[:]\n",
    "            lemma_seqs[i] = lemma_seq[:]\n",
    "\n",
    "            # If in training mode, popping the first element from sequences to shift the window\n",
    "            if mode == 'train':\n",
    "                x_seq.pop(0)\n",
    "                y_seq.pop(0)\n",
    "                word_seq.pop(0)\n",
    "                lemma_seq.pop(0)\n",
    "            else:                   # If not in training mode, reseting the sequences\n",
    "                x_seq = []\n",
    "                y_seq = []\n",
    "                word_seq = []\n",
    "                lemma_seq = []\n",
    "            i += 1\n",
    "\n",
    "            # If the batch is full, yield the data and reset for the next batch\n",
    "            if i >= B:\n",
    "                yield x, y, word_seqs, lemma_seqs\n",
    "                x = np.zeros((B, S, E))\n",
    "                y = np.zeros((B, S, E))\n",
    "                word_seqs = [None for _ in range(B)]\n",
    "                lemma_seqs = [None for _ in range(B)]\n",
    "                i = 0\n",
    "                word_count += S\n",
    "\n",
    "        try:             # Get word and lemma embeddings from the vector model\n",
    "            word_embedding = vec_model[word]\n",
    "            lemma_embedding = vec_model[lemma]\n",
    "        except KeyError:     # If not found, using zero vectors\n",
    "            word_embedding = np.zeros(E)\n",
    "            lemma_embedding = np.zeros(E)\n",
    "\n",
    "       # Appending the embeddings and the words/lemmas to the current sequences\n",
    "        x_seq.append(word_embedding)\n",
    "        y_seq.append(lemma_embedding)\n",
    "        word_seq.append(word)\n",
    "        lemma_seq.append(lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbd71dd",
   "metadata": {},
   "source": [
    "loaded test data using generate_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1d240be",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batches = [(x, y, w, l) for x, y, w, l in generate_data(test_words, test_lemmas, vec_model,line_limit=5154)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7dca5ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final test precision: 0.9795\n",
      "final test recall: 0.7148\n",
      "final test F1 score: 0.7258\n",
      "correctly lemmatized tokens: 3574\n",
      "all tokens: 5000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test set\n",
    "correct = 0\n",
    "count = 0\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Iterating through test batches containing X (input), Y (true labels),\n",
    "#  W (word embeddings), and L (lemmatized labels)\n",
    "for X, Y, W, L in test_batches:\n",
    "    \n",
    "    #Predicting labels using the LSTM model for the current batch\n",
    "    pred = LSTMmodel.predict_on_batch(X)\n",
    "    \n",
    "    # Iterating through predictions and sequences in the batch\n",
    "    for i, seq in enumerate(pred):\n",
    "        for j, pred_y in enumerate(seq):\n",
    "            # Checking if the input sequence is a padding sequence\n",
    "            if np.sum(X[i][j]) == 0:\n",
    "                nearest = W[i][j]   # If padding, use identity backoff for out-of-vocabulary (oov) tokens\n",
    "            else: # Find the nearest word embedding to the predicted label using a word vector model\n",
    "                nearest = vec_model.most_similar(positive=[pred_y], topn=1)[0][0]\n",
    "\n",
    "            true_labels.append(L[i][j])\n",
    "            predicted_labels.append(nearest)\n",
    "\n",
    "             # Checking if the predicted label matches the true label\n",
    "            if nearest == L[i][j]:\n",
    "                correct += 1\n",
    "            count += 1\n",
    "\n",
    "# Calculating precision, recall, and F1 score -> using prebuilt functions\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted',zero_division=1)\n",
    "\n",
    "print('final test precision: {0:.4f}'.format(precision))\n",
    "print('final test recall: {0:.4f}'.format(recall))\n",
    "print('final test F1 score: {0:.4f}'.format(f1))\n",
    "print('correctly lemmatized tokens:', correct)\n",
    "print('all tokens:', count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17319729",
   "metadata": {},
   "source": [
    "Evaluation on real-life examples to check our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7d0037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(tokens):\n",
    "    lemmas = []\n",
    "    for i in range(0, len(tokens), S):\n",
    "        x = np.zeros((1, S, E))\n",
    "        oov = []\n",
    "        \n",
    "        # Iterating through tokens in the current window and handle out-of-vocabulary cases\n",
    "        for j, t in enumerate(tokens[i:min(i + S, len(tokens))]):\n",
    "            try:\n",
    "                x[0][j] = vec_model[t]\n",
    "            except:\n",
    "                oov.append(j)\n",
    "                \n",
    "        #Predicting lemmas using the LSTM model for the current window        \n",
    "        y = LSTMmodel.predict([x], batch_size=1)\n",
    "        \n",
    "        # Iterating through the predicted values and handle out-of-vocabulary cases\n",
    "        predicted_lemmas = []\n",
    "        for j in range(min(i + S, len(tokens)) - i):\n",
    "            if j in oov: # If the token was out-of-vocabulary, keep the original token as the lemma\n",
    "                predicted_lemmas.append(tokens[i + j])\n",
    "            else: #Find the nearest word to the predicted value using the word vector model\n",
    "                predicted_lemmas.append(vec_model.most_similar(positive=[y[0][j]], topn=1)[0][0])\n",
    "        lemmas += predicted_lemmas    \n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62852be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Išao',\n",
       " 'biti',\n",
       " 'danas',\n",
       " 'na',\n",
       " 'posao,',\n",
       " 'biti',\n",
       " 'ja',\n",
       " 'biti',\n",
       " 'jako',\n",
       " 'zanimljiv',\n",
       " 'dan',\n",
       " 'na',\n",
       " 'poslu']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(\"Išao sam danas na posao, bio mi je jako zanimljiv dan na poslu\".split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6ea8af",
   "metadata": {},
   "source": [
    "**Final word:**\n",
    "    \n",
    "- Two models were tested to achieve text lemmatization using the HR500k dataset. \n",
    "- FeedFoward Neural network, was trained on the full dataset for training, evaluation and testing and achieved f1 score: 68.23%.\n",
    "- LSTM was trained on a smaller dataset 10 times due to resource limitations on the laptop, and f1 score was achieved on these data: 72.58%. \n",
    "\n",
    "My predictions are that LSTM on the full dataset would give a much better score, but I am satisfied with this achieved.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055ad0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
